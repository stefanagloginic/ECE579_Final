{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 7, 7])\n",
      "torch.Size([10, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "import sys;sys.path.insert(0, '..')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.randn(10, 7, 7)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "double_dims = nn.ConvTranspose2d(\n",
    "            10, 10, 2, stride=2)\n",
    "\n",
    "dd = double_dims(x)\n",
    "\n",
    "print(dd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "UNETMS(\n",
      "  (conv_layer_1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_layer_1_pool): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (conv_layer_2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_layer_2_pool): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (conv_layer_3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_layer_3_pool): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (conv_layer_4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_layer_4_pool): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (conv_layer_5): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_layer_6_transposed): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (cat_6): Concatlayer()\n",
      "  (conv_layer_6): Sequential(\n",
      "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_layer_7_transposed): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (cat_7): Concatlayer()\n",
      "  (conv_layer_7): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_layer_8_transposed): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (cat_8): Concatlayer()\n",
      "  (conv_layer_8): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_layer_9_transposed): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (cat_9): Concatlayer()\n",
      "  (conv_layer_9): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (cat_image_heatmap): Concatlayer()\n",
      "  (stage_2_conv_layer_1): Sequential(\n",
      "    (0): Conv2d(27, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (output): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 96, 96]           1,792\n",
      "              ReLU-2           [-1, 64, 96, 96]               0\n",
      "            Conv2d-3           [-1, 64, 96, 96]          36,928\n",
      "              ReLU-4           [-1, 64, 96, 96]               0\n",
      "         MaxPool2d-5           [-1, 64, 48, 48]               0\n",
      "            Conv2d-6          [-1, 128, 48, 48]          73,856\n",
      "              ReLU-7          [-1, 128, 48, 48]               0\n",
      "            Conv2d-8          [-1, 128, 48, 48]         147,584\n",
      "              ReLU-9          [-1, 128, 48, 48]               0\n",
      "        MaxPool2d-10          [-1, 128, 24, 24]               0\n",
      "           Conv2d-11          [-1, 256, 24, 24]         295,168\n",
      "             ReLU-12          [-1, 256, 24, 24]               0\n",
      "           Conv2d-13          [-1, 256, 24, 24]         590,080\n",
      "             ReLU-14          [-1, 256, 24, 24]               0\n",
      "        MaxPool2d-15          [-1, 256, 12, 12]               0\n",
      "           Conv2d-16          [-1, 512, 12, 12]       1,180,160\n",
      "             ReLU-17          [-1, 512, 12, 12]               0\n",
      "           Conv2d-18          [-1, 512, 12, 12]       2,359,808\n",
      "             ReLU-19          [-1, 512, 12, 12]               0\n",
      "        MaxPool2d-20            [-1, 512, 6, 6]               0\n",
      "           Conv2d-21           [-1, 1024, 6, 6]       4,719,616\n",
      "             ReLU-22           [-1, 1024, 6, 6]               0\n",
      "           Conv2d-23           [-1, 1024, 6, 6]       9,438,208\n",
      "             ReLU-24           [-1, 1024, 6, 6]               0\n",
      "  ConvTranspose2d-25          [-1, 512, 12, 12]       2,097,664\n",
      "      Concatlayer-26         [-1, 1024, 12, 12]               0\n",
      "           Conv2d-27          [-1, 512, 12, 12]       4,719,104\n",
      "             ReLU-28          [-1, 512, 12, 12]               0\n",
      "           Conv2d-29          [-1, 512, 12, 12]       2,359,808\n",
      "             ReLU-30          [-1, 512, 12, 12]               0\n",
      "  ConvTranspose2d-31          [-1, 256, 24, 24]         524,544\n",
      "      Concatlayer-32          [-1, 512, 24, 24]               0\n",
      "           Conv2d-33          [-1, 256, 24, 24]       1,179,904\n",
      "             ReLU-34          [-1, 256, 24, 24]               0\n",
      "           Conv2d-35          [-1, 256, 24, 24]         590,080\n",
      "             ReLU-36          [-1, 256, 24, 24]               0\n",
      "  ConvTranspose2d-37          [-1, 128, 48, 48]         131,200\n",
      "      Concatlayer-38          [-1, 256, 48, 48]               0\n",
      "           Conv2d-39          [-1, 128, 48, 48]         295,040\n",
      "             ReLU-40          [-1, 128, 48, 48]               0\n",
      "           Conv2d-41          [-1, 128, 48, 48]         147,584\n",
      "             ReLU-42          [-1, 128, 48, 48]               0\n",
      "  ConvTranspose2d-43           [-1, 64, 96, 96]          32,832\n",
      "      Concatlayer-44          [-1, 128, 96, 96]               0\n",
      "           Conv2d-45           [-1, 64, 96, 96]          73,792\n",
      "             ReLU-46           [-1, 64, 96, 96]               0\n",
      "           Conv2d-47           [-1, 64, 96, 96]          36,928\n",
      "             ReLU-48           [-1, 64, 96, 96]               0\n",
      "           Conv2d-49           [-1, 24, 96, 96]           1,560\n",
      "      Concatlayer-50           [-1, 27, 96, 96]               0\n",
      "           Conv2d-51           [-1, 64, 96, 96]          15,616\n",
      "             ReLU-52           [-1, 64, 96, 96]               0\n",
      "           Conv2d-53           [-1, 64, 96, 96]          36,928\n",
      "             ReLU-54           [-1, 64, 96, 96]               0\n",
      "        MaxPool2d-55           [-1, 64, 48, 48]               0\n",
      "           Conv2d-56          [-1, 128, 48, 48]          73,856\n",
      "             ReLU-57          [-1, 128, 48, 48]               0\n",
      "           Conv2d-58          [-1, 128, 48, 48]         147,584\n",
      "             ReLU-59          [-1, 128, 48, 48]               0\n",
      "        MaxPool2d-60          [-1, 128, 24, 24]               0\n",
      "           Conv2d-61          [-1, 256, 24, 24]         295,168\n",
      "             ReLU-62          [-1, 256, 24, 24]               0\n",
      "           Conv2d-63          [-1, 256, 24, 24]         590,080\n",
      "             ReLU-64          [-1, 256, 24, 24]               0\n",
      "        MaxPool2d-65          [-1, 256, 12, 12]               0\n",
      "           Conv2d-66          [-1, 512, 12, 12]       1,180,160\n",
      "             ReLU-67          [-1, 512, 12, 12]               0\n",
      "           Conv2d-68          [-1, 512, 12, 12]       2,359,808\n",
      "             ReLU-69          [-1, 512, 12, 12]               0\n",
      "        MaxPool2d-70            [-1, 512, 6, 6]               0\n",
      "           Conv2d-71           [-1, 1024, 6, 6]       4,719,616\n",
      "             ReLU-72           [-1, 1024, 6, 6]               0\n",
      "           Conv2d-73           [-1, 1024, 6, 6]       9,438,208\n",
      "             ReLU-74           [-1, 1024, 6, 6]               0\n",
      "  ConvTranspose2d-75          [-1, 512, 12, 12]       2,097,664\n",
      "      Concatlayer-76         [-1, 1024, 12, 12]               0\n",
      "           Conv2d-77          [-1, 512, 12, 12]       4,719,104\n",
      "             ReLU-78          [-1, 512, 12, 12]               0\n",
      "           Conv2d-79          [-1, 512, 12, 12]       2,359,808\n",
      "             ReLU-80          [-1, 512, 12, 12]               0\n",
      "  ConvTranspose2d-81          [-1, 256, 24, 24]         524,544\n",
      "      Concatlayer-82          [-1, 512, 24, 24]               0\n",
      "           Conv2d-83          [-1, 256, 24, 24]       1,179,904\n",
      "             ReLU-84          [-1, 256, 24, 24]               0\n",
      "           Conv2d-85          [-1, 256, 24, 24]         590,080\n",
      "             ReLU-86          [-1, 256, 24, 24]               0\n",
      "  ConvTranspose2d-87          [-1, 128, 48, 48]         131,200\n",
      "      Concatlayer-88          [-1, 256, 48, 48]               0\n",
      "           Conv2d-89          [-1, 128, 48, 48]         295,040\n",
      "             ReLU-90          [-1, 128, 48, 48]               0\n",
      "           Conv2d-91          [-1, 128, 48, 48]         147,584\n",
      "             ReLU-92          [-1, 128, 48, 48]               0\n",
      "  ConvTranspose2d-93           [-1, 64, 96, 96]          32,832\n",
      "      Concatlayer-94          [-1, 128, 96, 96]               0\n",
      "           Conv2d-95           [-1, 64, 96, 96]          73,792\n",
      "             ReLU-96           [-1, 64, 96, 96]               0\n",
      "           Conv2d-97           [-1, 64, 96, 96]          36,928\n",
      "             ReLU-98           [-1, 64, 96, 96]               0\n",
      "           Conv2d-99           [-1, 24, 96, 96]           1,560\n",
      "================================================================\n",
      "Total params: 62,080,304\n",
      "Trainable params: 62,080,304\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 197.37\n",
      "Params size (MB): 236.82\n",
      "Estimated Total Size (MB): 434.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test Model\n",
    "\n",
    "from torchsummary import summary\n",
    "from src.UNETMS import UNETMS\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "model = UNETMS().to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "summary(model, (3, 96, 96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: torch.Size([2, 24, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "# Pass random tensor into model\n",
    "# 4 dimensions as input expected: N, C, H, W\n",
    "rand_img = torch.rand(2, 3, 96, 96, device=device)\n",
    "result = model(rand_img)\n",
    "print(f\"Predicted class: {result.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece_579_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
